{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-56.61951136331\n"
     ]
    }
   ],
   "source": [
    "import gdal\n",
    "import ogr \n",
    "\n",
    "ds = ogr.Open(\"./test_chips.shp\")\n",
    "layer = ds.GetLayer()\n",
    "\n",
    "test_chips_coords = []\n",
    "\n",
    "for i in range(0,250):\n",
    "\n",
    "    feature = layer.GetFeature(i)\n",
    "\n",
    "    coords = list(feature)[1:5]\n",
    "\n",
    "    test_chips_coords.append(dict([(\"ulx\", coords[0]), (\"uly\", coords[1]), (\"lrx\", coords[2]), (\"lry\", coords[3])]))\n",
    "\n",
    "print(test_chips_coords[0][\"ulx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "def parse_data(data):\n",
    "    \n",
    "    features_for_data = {\n",
    "        'b1': tf.io.FixedLenFeature([256,256], tf.float32),\n",
    "        'b2': tf.io.FixedLenFeature([256,256], tf.float32),\n",
    "        'b3':tf.io.FixedLenFeature([256,256], tf.float32),\n",
    "        'ref': tf.io.FixedLenFeature([256,256], tf.float32)\n",
    "    }\n",
    "    \n",
    "    data = tf.io.parse_single_example(data, features_for_data)\n",
    "    inputsList_data = [data.get(key) for key in ['b1', 'b2', 'b3']]\n",
    "    stacked_data = tf.stack(inputsList_data, axis=0)\n",
    "    stacked_data = tf.transpose(stacked_data, [1,2,0])\n",
    "\n",
    "    inputsList_ref =  [data.get(key) for key in ['ref']]\n",
    "    stacked_ref = tf.stack(inputsList_ref, axis=0)\n",
    "    stacked_ref = tf.transpose(stacked_ref, [1,2,0])\n",
    "\n",
    "    return stacked_data[:,:,:3], stacked_ref[:,:,:]\n",
    "\n",
    "def get_data():\n",
    "\n",
    "    training_files = \"../data/training_buffered_2x.tfrecord\"\n",
    "    validation_files = \"../data/validation_buffered_2x.tfrecord\"\n",
    "    test_files = \"../data/test_buffered_2x.tfrecord\"\n",
    "    \n",
    "    files_set = [training_files, validation_files, test_files]\n",
    "    data_sets = []\n",
    "    \n",
    "    for i in files_set:\n",
    "        files = tf.io.gfile.glob(i)\n",
    "        files = tf.data.TFRecordDataset(files, compression_type=None)\n",
    "        \n",
    "        data_sets.append(files.map(parse_data))\n",
    "        \n",
    "    return data_sets[0], data_sets[1], data_sets[2]\n",
    "\n",
    "def soft_dice_loss(y_pred, y_true, smooth = 1):\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "   \n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    dice = K.abs(2. * intersection + smooth) / (K.abs(K.sum(K.square(y_true_f))) + K.abs(K.sum(K.square(y_pred_f))) + smooth)\n",
    "    \n",
    "    return 1-K.mean(dice)\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "best_model_soft_dice = tf.keras.models.load_model(\"../estrutura_modelo\", custom_objects={'recall_m': recall_m, 'f1_m': f1_m, 'precision_m': precision_m, 'loss function': soft_dice_loss}, compile=False)\n",
    "best_model_soft_dice.compile(loss=soft_dice_loss, metrics=[recall_m, f1_m, precision_m])\n",
    "\n",
    "training_set, validation_set, test_set = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./predicted/Test_chip_0.tif']\n",
      "Etapa de divisão do mosaico de água em cartas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./mascara_de_agua/Test_agua.tif']\n",
      "Etapa de aplicação da máscara de água\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./predicted/Test_chip_0.tif\n",
      "./mascara_de_agua/Test_agua.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./mascarados/test_masked.tif']\n",
      "Etapa de snapping e skeletização do dados do raster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 66.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etapa de vetorização dos dados\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "CalledModuleError",
     "evalue": "Module run None g.remove -f type=all pattern=tmp* ended with error\nProcess ended with non-zero return code 3221225781. See errors in the (error) output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledModuleError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23548/1231987088.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[0mcarta_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m             \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"g.remove\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"f\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"all\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"tmp*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m             \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"v.in.ogr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcharts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"charts\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"v.in.ogr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscenes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"scenes\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\GRASS GIS 7.8\\etc\\python\\grass\\script\\core.py\u001b[0m in \u001b[0;36mrun_command\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[0mreturncode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturncode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\GRASS GIS 7.8\\etc\\python\\grass\\script\\core.py\u001b[0m in \u001b[0;36mhandle_errors\u001b[1;34m(returncode, result, args, kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m         raise CalledModuleError(module=None, code=code,\n\u001b[0m\u001b[0;32m    343\u001b[0m                                 returncode=returncode)\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCalledModuleError\u001b[0m: Module run None g.remove -f type=all pattern=tmp* ended with error\nProcess ended with non-zero return code 3221225781. See errors in the (error) output."
     ]
    }
   ],
   "source": [
    "import gdal\n",
    "import osr\n",
    "import gdalconst\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from skimage.morphology import skeletonize, binary_closing, rectangle\n",
    "from skimage.transform import rotate\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from grass_session import Session\n",
    "import grass.script.core as gs\n",
    "\n",
    "def water_masks(predicted_images, water_raster_path):\n",
    "    \n",
    "    print(\"Etapa de divisão do mosaico de água em cartas\")\n",
    "    for i in tqdm(predicted_images):\n",
    "        pred = gdal.Open(i)\n",
    "        # print(pred)\n",
    "        xsize = pred.RasterXSize\n",
    "        ysize = pred.RasterYSize\n",
    "        \n",
    "        ulx, xres, xskew, uly, yskew, yres = pred.GetGeoTransform()\n",
    "        lrx = ulx + (xsize * xres)\n",
    "        lry = uly + (ysize * yres)\n",
    "        \n",
    "        carta_name = i.split(\"/\")[-1].split(\"_\")[0]\n",
    "        \n",
    "        outfile = \"./mascara_de_agua/{}_agua.tif\".format(carta_name)\n",
    "        \n",
    "        gdal.Translate(outfile, water_raster_path, projWin=[ulx,uly,lrx,lry], width=xsize, height=ysize, creationOptions=['TFW=YES', 'COMPRESS=LZW'])\n",
    "        \n",
    "        pred = None\n",
    "        \n",
    "    \n",
    "def water_masks_application(predicted_images, water_masks):\n",
    "    \n",
    "    print(\"Etapa de aplicação da máscara de água\")\n",
    "    for x,y in tqdm(zip(predicted_images, water_masks)):\n",
    "        print(x)\n",
    "        print(y)\n",
    "        carta_name = x.split(\"/\")[-1].split(\"_\")[0]\n",
    "        # print(carta_name)\n",
    "        outfile = \"./mascarados/{}_masked.tif\".format(carta_name)\n",
    " \n",
    "        os.system('python C:/Users/jonas/anaconda3/envs/research/Scripts/gdal_calc.py -A {x} -B {y} --outfile={outfile} --NoDataValue=0 --calc=\"A-(B>0)\" --creation-option \"TFW=YES\" --creation-option \"COMPRESS=LZW\" --quiet --overwrite')\n",
    "\n",
    "        # startcmd=[\"python3.exe\", \"gdal_calc.py\", \"-A\", x, \"-B\", y, \"--outfile\" ,outfile, \"--NoDataValue\", \"0\", \"--calc\", \"A-(B>0)\", \"--creation-option\", 'TFW=YES', \"--creation-option\", 'COMPRESS=LZW', \"--quiet\", \"--overwrite\"]\n",
    "\n",
    "        # subprocess.call(startcmd)\n",
    "\n",
    "        pred = None\n",
    "        water = None\n",
    "        \n",
    "def skeletonize_tif(masked):\n",
    "    \n",
    "    print(\"Etapa de snapping e skeletização do dados do raster\")\n",
    "    for i in tqdm(masked):\n",
    "        mascarado = gdal.Open(i)\n",
    "        \n",
    "        carta_name = i.split(\"/\")[-1].split(\"_\")[0]\n",
    "        \n",
    "        raster_array = mascarado.GetRasterBand(1).ReadAsArray()\n",
    "        \n",
    "        xsize = mascarado.RasterXSize + 1\n",
    "        ysize = mascarado.RasterYSize + 1\n",
    "        \n",
    "        ulx, xres, xskew, uly, yskew, yres = mascarado.GetGeoTransform()\n",
    "        lrx = ulx + (xsize * xres)\n",
    "        lrx = uly + (ysize * yres)\n",
    "        \n",
    "        masked_skeleton = skeletonize(raster_array).astype(np.uint8)\n",
    "        \n",
    "        dilation = binary_closing(masked_skeleton, rectangle(10,1))\n",
    "        dilation = binary_closing(dilation, rectangle(1,10))\n",
    "        dilation = binary_closing(dilation, rotate(rectangle(1,10), 45))\n",
    "        dilation = binary_closing(dilation, rotate(rectangle(1,10), 135))\n",
    "        \n",
    "        dilation = binary_closing(dilation, rotate(rectangle(10,1), 45))\n",
    "        dilation = binary_closing(dilation, rotate(rectangle(10,1), 135))\n",
    "        \n",
    "        array_skeleton = skeletonize(dilation).astype(np.uint8)\n",
    "        \n",
    "        output_raster = gdal.GetDriverByName('GTiff').Create('./skeleton/skeleton_{}.tif'.format(carta_name), xsize, ysize, 1, gdalconst.GDT_Byte)\n",
    "        output_raster.SetGeoTransform(mascarado.GetGeoTransform())\n",
    "        output_raster.GetRasterBand(1).WriteArray(array_skeleton)\n",
    "        srs = osr.SpatialReference()\n",
    "        srs.ImportFromEPSG(4326)\n",
    "        \n",
    "        output_raster.SetProjection(srs.ExportToWkt())\n",
    "        \n",
    "        output_raster.FlushCache()\n",
    "        \n",
    "        mascarado = None\n",
    "    \n",
    "def vectorize(raster, carta_name):\n",
    "    \n",
    "    gs.run_command(\"r.in.gdal\", input=raster, output=\"chart_raster\", overwrite=True)\n",
    "    \n",
    "    gs.run_command(\"g.region\", raster=\"chart_raster\", overwrite=True)\n",
    "    \n",
    "    gs.run_command(\"r.null\", map=\"chart_raster\", setnull=[0])\n",
    "    gs.run_command(\"r.thin\", input=\"chart_raster\", output=\"chart_thinned\", iteration=10, overwrite=True)\n",
    "    gs.run_command(\"r.to.vect\", input=\"chart_thinned\", output=\"chart_vector\", type=\"line\", overwrite=True)\n",
    "    \n",
    "    #Limpeza 1 -> Linhas que se tocam e segmentos maiores que 1km\n",
    "    gs.run_command(\"v.generalize\", input=\"chart_vector\", output=\"chart_vector_smoothed\", method=\"snake\", iterations=5, threshold=0.5, angle=180, overwrite=True)\n",
    "    gs.run_command(\"v.build\", map=\"chart_vector_smoothed\", error=\"error\", option=\"build\", overwrite=True)\n",
    "    gs.run_command(\"v.to.db\", map=\"chart_vector_smoothed\", option=\"length\", type=\"line\", columns=\"len\", units=\"me\")\n",
    "    gs.run_command(\"v.select\", ainput=\"chart_vector_smoothed\", atype=\"line\", binput=\"chart_vector_smoothed\", btype=\"line\", output=\"connected_lines\", operator=\"touches\", overwrite=True)\n",
    "    gs.run_command(\"v.edit\", map=\"chart_vector_smoothed\", tool=\"delete\", type=\"line\", where=\"len < 1000\")\n",
    "    gs.run_command(\"v.patch\", input=[\"chart_vector_smoothed\", \"connected_lines\"], output=\"filtered_chart\", overwrite=True)\n",
    "    \n",
    "    #Limpeza 2 -> Borda das cartas\n",
    "    gs.run_command(\"v.select\", ainput=\"charts\", atype=\"area\", binput=\"filtered_chart\", btype=\"line\", output=\"chart\", operator=\"contains\", overwrite=True)\n",
    "    gs.run_command(\"v.to.lines\", input=\"chart\", output=\"chart_limits\", overwrite=True)\n",
    "    gs.run_command(\"v.buffer\", input=\"chart_limits\", distance=0.0005, output=\"chart_limits_buffered\", overwrite=True)\n",
    "    gs.run_command(\"v.select\", ainput=\"filtered_chart\", atype=\"line\", binput=\"chart_limits_buffered\", btype=\"area\", output=\"border_lines\", operator=\"within\", overwrite=True)\n",
    "    gs.run_command(\"v.select\", ainput=\"filtered_chart\", atype=\"line\", binput=\"border_lines\", operator=\"equals\", output=\"chart_border_cleaned\", overwrite=True, flags=\"r\")\n",
    "    \n",
    "    #Limpeza 3 -> Borda das cenas\n",
    "    gs.run_command(\"v.select\", ainput=\"scenes\", atype=\"area\", binput=\"chart_border_cleaned\", btype=\"line\", output=\"scenes_intersect\", operator=\"intersects\", overwrite=True)\n",
    "    gs.run_command(\"v.select\", ainput=\"chart_border_cleaned\", atype=\"line\", binput=\"scenes_intersect\", btype=\"area\", output=\"scenes_lines\", operator=\"within\", overwrite=True)\n",
    "#     gs.run_command(\"v.build\", map=\"scenes_lines\", error=\"error\", option=\"build\", overwrite=True)\n",
    "#     try:\n",
    "# #         print(gs.parse_command(\"\"))\n",
    "#         print(gs.parse_command(\"db.tables\", flags=\"p\"))\n",
    "    gs.run_command(\"v.db.addtable\", map=\"scenes_lines\")\n",
    "    gs.run_command(\"v.db.connect\", map=\"scenes_lines\", table=\"scenes_lines\", flags=\"o\")\n",
    "#         gs.run_command(\"v.db.addcolumn\", map=\"scenes_lines\", columns=\"angle double precision, len double precision\")\n",
    "#         gs.run_command(\"v.to.db\", map=\"scenes_lines\", option=\"length\", type=\"line\", columns=\"len\", units=\"me\", overwrite=True)\n",
    "#         gs.run_command(\"v.to.db\", map=\"scenes_lines\", option=\"azimuth\", type=\"line\", columns=\"angle\", units=\"degrees\", overwrite=True)\n",
    "#     except:\n",
    "#     print(gs.parse_command(\"db.tables\", flags=\"p\"))\n",
    "    gs.run_command(\"v.to.db\", map=\"scenes_lines\", option=\"length\", type=\"line\", columns=\"len\", units=\"me\", overwrite=True)\n",
    "    gs.run_command(\"v.to.db\", map=\"scenes_lines\", option=\"azimuth\", type=\"line\", columns=\"angle\", units=\"degrees\", overwrite=True)\n",
    "    gs.run_command(\"v.extract\", input=\"scenes_lines\", type=\"line\", where=\"((angle >= 89 and angle <= 91 ) or (angle >= -1 and angle <= 1) or (angle >= 179 and angle <= 181) or (angle >= 269 and angle <= 271) or (angle >= 359 and angle <= 361)) and (len > 500)\", output=\"scenes_lines_filtered\", overwrite=True)\n",
    "#     gs.run_command(\"v.db.addtable\", map=\"scenes_lines_filtered\")\n",
    "#     gs.run_command(\"v.db.connect\", map=\"scenes_lines_filtered\", table=\"scenes_lines_filtered\", flags=\"o\")\n",
    "#     gs.run_command(\"v.extract\", input=\"scenes_lines_filtered\", type=\"line\", where=\"len > 500\", output=\"scenes_lines_filtered_2\", overwrite=True)\n",
    "    gs.run_command(\"v.select\", ainput=\"chart_border_cleaned\", atype=\"line\", binput=\"scenes_lines_filtered\", operator=\"equals\", output=\"chart_border_cleaned_scenes\", overwrite=True, flags=\"r\")\n",
    "\n",
    "    #Limpeza 4 -> Densidade de estradas\n",
    "    gs.run_command(\"v.mkgrid\", map=\"grid\", position=\"region\", box=[0.0901404892, 0.0901404892], overwrite=True)\n",
    "    gs.run_command(\"v.overlay\", ainput=\"chart_border_cleaned_scenes\", atype=\"line\", binput=\"grid\", btype=\"area\", operator=\"and\", output=\"lines_divided\", overwrite=True)\n",
    "    gs.run_command(\"v.overlay\", ainput=\"chart_border_cleaned_scenes\", atype=\"line\", binput=\"grid\", btype=\"area\", operator=\"not\", output=\"lines_outside_grid\", overwrite=True)\n",
    "    gs.run_command(\"v.to.db\", map=\"lines_divided\", option=\"length\", type=\"line\", columns=\"len\", units=\"me\")\n",
    "\n",
    "    try:\n",
    "        gs.run_command(\"db.execute\", driver=\"sqlite\", sql=\"DROP TABLE grid_density\")\n",
    "    except:\n",
    "        print(\"Não precisa deletar tabela\")\n",
    "    gs.run_command(\"db.execute\", driver=\"sqlite\", sql=\"CREATE TABLE grid_density as SELECT a.cat, CAST(SUM(b.len) as double precision) as density FROM grid a, lines_divided b WHERE a.cat = b.b_cat group by a.cat\")\n",
    "    gs.run_command(\"v.db.join\", map=\"grid\", column=\"cat\", other_table=\"grid_density\", other_column=\"cat\")\n",
    "    gs.run_command(\"v.extract\", input=\"grid\", type=\"area\", where=\"density > 10000\", output=\"grid_chosen\", overwrite=True)\n",
    "    gs.run_command(\"v.select\", ainput=\"lines_divided\", atype=\"line\", binput=\"grid_chosen\", operator=\"intersects\", output=\"chart_filtered\", overwrite=True)\n",
    "    gs.run_command(\"v.patch\", input=[\"chart_filtered\", \"lines_outside_grid\"], output=\"chart_cleaned\", overwrite=True)\n",
    "    gs.run_command(\"v.out.ogr\", input=\"chart_cleaned\", output=\"./vetor/{}_vector.shp\".format(carta_name), format=\"ESRI_Shapefile\", overwrite=True)\n",
    "    \n",
    "    \n",
    "def rasterize(raster, carta_name):\n",
    "    \n",
    "    outfile_10 = \"./raster/raster_10/{}_raster_10.tif\".format(carta_name)\n",
    "    outfile_1000 = \"./raster/raster_1000/{}_raster_1000.tif\".format(carta_name)\n",
    "    \n",
    "    !gdal_rasterize -burn 1 -of GTiff -a_nodata 0 -co 'TFW=YES' -co 'COMPRESS=LZW' -tr 9.014048920182702478e-05 9.014048920182702478e-05 {i} {outfile_10}\n",
    "    !gdal_rasterize -burn 1 -of GTiff -a_nodata 0 -co 'TFW=YES' -co 'COMPRESS=LZW' -tr 0.00901404892 0.00901404892 {i} {outfile_1000}\n",
    "    \n",
    "def mosaics(vectors, rasters_10, raster_1000):\n",
    "    \n",
    "#     gdal.BuildVRT(\"./mosaicos/mosaic_raster_10.vrt\", rasters_10)\n",
    "#     gdal.BuildVRT(\"./mosaicos/mosaic_raster_1000.vrt\", raster_1000)\n",
    "    \n",
    "#     gdal.Translate(\"./mosaicos/mosaic_raster_10.tif\", \"./mosaicos/mosaic_raster_10.vrt\", outputType=gdalconst.GDT_Byte, creationOptions=['TFW=YES', 'COMPRESS=LZW'])\n",
    "#     gdal.Translate(\"./mosaicos/mosaic_raster_1000.tif\", \"./mosaicos/mosaic_raster_1000.vrt\", outputType=gdalconst.GDT_Byte, creationOptions=['TFW=YES', 'COMPRESS=LZW'])\n",
    "    \n",
    "    !ogrmerge.py -single -o ./mosaicos/mosaic_vector_amazon.shp {\" \".join(vectors)} \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "#     Primeira Etapa - Divisão do mosaico de água por cartas\n",
    "    predicted_images = [glob.glob(\"./predicted/*.tif\")[0].replace(\"\\\\\", \"/\")]\n",
    "    print(predicted_images)\n",
    "    # skeleton_fixed_list = [\"./skeleton/skeleton_\" + i.split(\"/\")[-1].split(\"_\")[0] + \".tif\" for i in ['SB-18-Z-A', 'SB-19-Y-A', 'NB-20-Y-D', 'SB-19-Z-C', 'SC-19-Y-A']]\n",
    "    \n",
    "    water_raster_path = \"./auxiliar/aguas_amazonia_buffered.tif\"\n",
    "    water_masks(predicted_images, water_raster_path)\n",
    "    \n",
    "#     Segunda Etapa - Aplicação da máscara de água\n",
    "    water_masked = [glob.glob(\"./mascara_de_agua/*.tif\")[0].replace(\"\\\\\", \"/\")]\n",
    "    print(water_masked)\n",
    "    # water_masked_fixed = [i for i in water_masked if i is in ]\n",
    "    water_masks_application(predicted_images, water_masked)\n",
    "    # water_masks_application(predicted_images, water_fixed_list)\n",
    "    \n",
    "#     Terceira Etapa - Snapping e Skeletização\n",
    "    masked = [glob.glob(\"./mascarados/*.tif\")[0].replace(\"\\\\\", \"/\")]\n",
    "    print(masked)\n",
    "    skeletonize_tif(masked)\n",
    "    \n",
    "#     #Quarta Etapa - Vetorização\n",
    "    skeletons = glob.glob(\"./skeleton/*.tif\")\n",
    "    charts = \"./auxiliar/Amazonia_legal_cartas.shp\"\n",
    "    scenes = \"./auxiliar/grid_sentinel_amazonia_legal_certo.geojson\"\n",
    "    \n",
    "    with Session(gisdb=\"/tmp\", location=\"amazonia\", create_opts=\"EPSG:4326\"):\n",
    "        \n",
    "        gs.set_raise_on_error(True)\n",
    "        gs.set_capture_stderr(True)\n",
    "        \n",
    "        print(\"Etapa de vetorização dos dados\")\n",
    "                              \n",
    "        for i in tqdm(skeletons):\n",
    "            carta_name = i.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "            gs.run_command(\"g.remove\", flags=\"f\", type=\"all\", pattern=\"tmp*\")\n",
    "            gs.run_command(\"v.in.ogr\", input=charts, output=\"charts\", overwrite=True)\n",
    "            gs.run_command(\"v.in.ogr\", input=scenes, output=\"scenes\", overwrite=True)\n",
    "\n",
    "            vectorize(i, carta_name)\n",
    "            \n",
    "    # vectors = glob.glob(\"./vetor/*.shp\")\n",
    "#     print(len(vectors))\n",
    "\n",
    "#     #Quinta Etapa - Rasterização\n",
    "#     print(\"Etapa de rasterização dos vetores\")\n",
    "#     for i in tqdm(vectors):\n",
    "#         carta_name = i.split(\"/\")[-1].split(\"_\")[0]\n",
    "#         rasterize(i, carta_name)\n",
    "        \n",
    "    # raster_10 = glob.glob(\"./raster/raster_10/*.tif\")\n",
    "    # raster_1000 = glob.glob(\"./raster/raster_1000/*.tif\")\n",
    "    \n",
    "    #Sexta Etapa - Composição dos mosaicos\n",
    "    # print(\"Etapa de montagem dos mosaicos\")\n",
    "    # mosaics(vectors, raster_10, raster_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "grass7bin_win = 'C:/\"Program Files\"/\"GRASS GIS 7.8\"/grass78.bat'\n",
    "grass7bin = grass7bin_win\n",
    "\n",
    "os.environ[\"GRASSBIN\"] = grass7bin_win\n",
    "\n",
    "startcmd = grass7bin + ' --config path'\n",
    "\n",
    "p = subprocess.Popen(startcmd, shell=True, \n",
    "                 stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "out, err = p.communicate()\n",
    "\n",
    "if p.returncode != 0:\n",
    " print (sys.stderr, 'ERROR: %s' % err)\n",
    " print (sys.stderr, \"ERROR: Cannot find GRASS GIS 7.8 start script (%s)\" % startcmd)\n",
    " sys.exit(-1)\n",
    "gisbase = out.strip(b'\\n\\r')\n",
    "gisbase = gisbase.decode(\"utf-8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GISBASE'] = gisbase \n",
    "os.environ['PATH'] += os.pathsep + os.path.join(gisbase, 'extrabin')\n",
    "home = os.path.expanduser(\"~\")\n",
    "os.environ['PATH'] += os.pathsep + os.path.join(home, '.grass7', 'addons', 'scripts')\n",
    "gpydir = os.path.join(gisbase, \"etc\", \"Python\")\n",
    "sys.path.append(gpydir)\n",
    "gisdb = os.path.join(os.path.expanduser(\"~\"), \"Documents\\grassdata\")\n",
    "os.environ['GISDBASE'] = gisdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "# grass7bin = r'C:\\Program Files\\QGIS 3.20.2\\bin\\grass78.bat'\n",
    "# \n",
    "# query GRASS 7 itself for its GISBASE\n",
    "# startcmd = [grass7bin, '--config', 'path']\n",
    "\n",
    "# p = subprocess.Popen(startcmd, shell=False,\n",
    "#                      stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "# out, err = p.communicate()\n",
    "# if p.returncode != 0:\n",
    "#     print >>sys.stderr, \"ERROR: Cannot find GRASS GIS 7 start script (%s)\" % startcmd\n",
    "#     sys.exit(-1)\n",
    "# print(out[0:-2])\n",
    "# gisbase = out[0:-2]\n",
    "# this could be replaced by using the right gisbase\n",
    "# directly instead of the executable\n",
    "# print(out)\n",
    "# Set GISBASE environment variable\n",
    "# os.environ['GISBASE'] = gisbase.decode()\n",
    "os.environ['GRASSBIN'] = 'C:/\"Program Files\"/\"GRASS GIS 7.8\"/grass78.bat'\n",
    "os.environ['GISBASE'] = 'C:/\"Program Files\"/\"GRASS GIS 7.8\"'\n",
    "# define GRASS-Python environment\n",
    "# gpydir = os.path.join(gisbase.decode(), \"etc\", \"python\")\n",
    "# sys.path.append(gpydir)\n",
    "\n",
    "# data\n",
    "# gisdb = os.path.join(os.path.expanduser(\"~\"), \"Documents/grassdata\")\n",
    "\n",
    "# specify (existing) location and mapset\n",
    "# location = \"amazonia\"\n",
    "# mapset = \"amz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osr\n",
    "import numpy as np\n",
    "\n",
    "def concat_infos(carta, predicted):\n",
    "    coords = carta[0]\n",
    "    print(coords)\n",
    "    predicted[predicted >= 0.2] = 1\n",
    "    predicted[predicted < 0.2] = 0\n",
    "    \n",
    "    return  predicted, coords\n",
    "\n",
    "#FUNÇÃO DE GEO-REFERENCIAMENTO DOS RESULTADOS DO MODELO\n",
    "def save_predicted(inf):\n",
    "    saved_predicted = []\n",
    "    # for i in inf:\n",
    "        \n",
    "    coords = inf[1]\n",
    "    # print(i)\n",
    "    xmin = coords[\"ulx\"]\n",
    "    ymax = coords[\"uly\"]\n",
    "#         xres = coords[2]\n",
    "#         yres = coords[3]\n",
    "    \n",
    "    geotransform=(xmin,9.014048920182260666e-05,0,ymax,0, -9.014048920182260666e-05)   \n",
    "\n",
    "    # output_raster = gdal.GetDriverByName('GTiff').Create('/vsimem/{}_{}.tif'.format(carta_name, num),256, 256, 1 ,gdal.GDT_Byte)  # Open the file\n",
    "    output_raster = gdal.GetDriverByName('GTiff').Create('./{}.tif'.format(\"Test_chip_0\"),256, 256, 1 ,gdal.GDT_Byte)  # Open the file\n",
    "    \n",
    "    output_raster.SetGeoTransform(geotransform)\n",
    "    srs = osr.SpatialReference()                \n",
    "    srs.ImportFromEPSG(4326)                    \n",
    "    \n",
    "    output_raster.SetProjection( srs.ExportToWkt() )  \n",
    "    output_raster.GetRasterBand(1).WriteArray(np.reshape(inf[0], (256,256)))\n",
    "    saved_predicted.append(output_raster)\n",
    "    output_raster.FlushCache()\n",
    "\n",
    "    return saved_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ulx': -56.61951136331, 'uly': -9.83166231658, 'lrx': -56.596514492039994, 'lry': -9.854659187849999}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<osgeo.gdal.Dataset; proxy of <Swig Object of type 'GDALDatasetShadow *' at 0x0000016517D80870> >]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_soft_dice_1 = best_model_soft_dice.predict(test_set.skip(0).take(1).batch(1))\n",
    "\n",
    "infos = concat_infos(test_chips_coords, predicted_soft_dice_1)\n",
    "# print(infos[1])\n",
    "save_predicted(infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.preprocessing as prep\n",
    "from skimage.morphology import skeletonize, binary_closing\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from IPython.display import display\n",
    "\n",
    "font = {'family': 'serif',\n",
    "        'color':  'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 12,\n",
    "}\n",
    "\n",
    "for x in range(0,5):\n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "\n",
    "    gs = GridSpec(1, 5, figure=fig)\n",
    "    gs.update(wspace=0.1, hspace=0.02)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "#     ax5 = fig.add_subplot(gs[0, 4])\n",
    "\n",
    "\n",
    "    for i in test_set.skip(x).take(1):\n",
    "        \n",
    "        img_original = prep.image.array_to_img(i[0])\n",
    "        ax1.imshow(img_original)\n",
    "        ax1.axis('off')\n",
    "        if x == 0:\n",
    "            ax1.set_title(\"(a)\", fontdict=font)\n",
    "        \n",
    "        img_original = prep.image.array_to_img(i[0])\n",
    "        ax2.imshow(img_original.split()[2], cmap=plt.cm.gray)\n",
    "        ax2.axis('off')\n",
    "        if x == 0:\n",
    "            ax2.set_title(\"(b)\", fontdict=font)\n",
    "\n",
    "        img = prep.image.array_to_img(i[1])\n",
    "        ax3.imshow(img, cmap=plt.cm.gray)\n",
    "        ax3.axis('off')\n",
    "        if x == 0:\n",
    "            ax3.set_title(\"(c)\", fontdict=font)\n",
    "\n",
    "\n",
    "    predicted_soft_dice_1 = best_model_soft_dice.predict(test_set.skip(x).take(1).batch(1))\n",
    "\n",
    "    # predicted_soft_dice_1[predicted_soft_dice_1 < 0.2] = 0\n",
    "    # predicted_soft_dice_1[predicted_soft_dice_1 > 0.2] = 1\n",
    "    predicted_soft_dice_1 = prep.image.array_to_img(predicted_soft_dice_1[0])\n",
    "\n",
    "    ax4.imshow(predicted_soft_dice_1, cmap=plt.cm.gray)\n",
    "    ax4.axis('off')\n",
    "    if x == 0:\n",
    "        ax4.set_title(\"(d)\", fontdict=font)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e673f1f71382f1c289e42c8b903c5f32c273857636108dc41a5a79520a08e68"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('research': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
